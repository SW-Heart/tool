"""
æ–°é—»æ•°æ®å­˜å‚¨å±‚ - SQLite
è§„åˆ™ï¼šåªä¿ç•™24å°æ—¶å†…çš„æ•°æ®ï¼Œè¿‡æœŸè‡ªåŠ¨æ¸…ç†
"""

import sqlite3
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional
from contextlib import contextmanager


class NewsStorage:
    """æ–°é—»æ•°æ®å­˜å‚¨ - 24å°æ—¶æ»šåŠ¨çª—å£"""
    
    # æ•°æ®ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    RETENTION_HOURS = 24
    
    def __init__(self, db_path: Optional[str] = None):
        self.db_path = Path(db_path) if db_path else Path("./data/news.db")
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()
    
    @contextmanager
    def _get_conn(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(str(self.db_path))
        conn.row_factory = sqlite3.Row
        try:
            yield conn
            conn.commit()
        finally:
            conn.close()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with self._get_conn() as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS news (
                    id TEXT PRIMARY KEY,
                    source TEXT NOT NULL,
                    title TEXT NOT NULL,
                    content TEXT,
                    link TEXT,
                    publish_time TEXT,
                    crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    is_important BOOLEAN DEFAULT 0,
                    extra_data TEXT
                )
            ''')
            # åˆ›å»ºç´¢å¼•åŠ é€ŸæŸ¥è¯¢
            conn.execute('CREATE INDEX IF NOT EXISTS idx_crawled_at ON news(crawled_at)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_source ON news(source)')
            # æ·»åŠ  link å”¯ä¸€ç´¢å¼•é˜²æ­¢é‡å¤
            conn.execute('CREATE UNIQUE INDEX IF NOT EXISTS idx_link ON news(link)')
    
    def save_news(self, news_list: list[dict]) -> int:
        """
        ä¿å­˜æ–°é—»åˆ—è¡¨
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            æ–°å¢çš„æ¡æ•°
        """
        inserted = 0
        with self._get_conn() as conn:
            for news in news_list:
                try:
                    conn.execute('''
                        INSERT OR IGNORE INTO news 
                        (id, source, title, content, link, publish_time, crawled_at, is_important, extra_data)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        news.get('id'),
                        news.get('source', 'unknown'),
                        news.get('title', ''),
                        news.get('content', ''),
                        news.get('link', ''),
                        news.get('time', ''),
                        news.get('crawled_at', datetime.now().isoformat()),
                        1 if news.get('isImportant') else 0,
                        json.dumps(news.get('extra', {}), ensure_ascii=False)
                    ))
                    if conn.total_changes > 0:
                        inserted += 1
                except sqlite3.IntegrityError:
                    pass  # é‡å¤æ•°æ®è·³è¿‡
        
        return inserted
    
    def get_latest_news(self, limit: int = 20, source: Optional[str] = None) -> list[dict]:
        """
        è·å–æœ€æ–°æ–°é—»
        
        Args:
            limit: è¿”å›æ¡æ•°
            source: æ¥æºç­›é€‰ï¼ˆå¦‚ 'PANews'ï¼‰
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        with self._get_conn() as conn:
            if source:
                cursor = conn.execute('''
                    SELECT * FROM news 
                    WHERE source = ? 
                    ORDER BY crawled_at DESC 
                    LIMIT ?
                ''', (source, limit))
            else:
                cursor = conn.execute('''
                    SELECT * FROM news 
                    ORDER BY crawled_at DESC 
                    LIMIT ?
                ''', (limit,))
            
            return [dict(row) for row in cursor.fetchall()]
    
    def get_news_since(self, since_id: str) -> list[dict]:
        """
        è·å–æŸæ¡æ–°é—»ä¹‹åçš„æ‰€æœ‰æ–°é—»
        
        Args:
            since_id: èµ·å§‹æ–°é—»IDï¼ˆä¸åŒ…å«ï¼‰
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        with self._get_conn() as conn:
            # å…ˆè·å–è¯¥IDçš„æ—¶é—´
            cursor = conn.execute(
                'SELECT crawled_at FROM news WHERE id = ?', 
                (since_id,)
            )
            row = cursor.fetchone()
            if not row:
                return []
            
            since_time = row['crawled_at']
            
            cursor = conn.execute('''
                SELECT * FROM news 
                WHERE crawled_at > ? 
                ORDER BY crawled_at ASC
            ''', (since_time,))
            
            return [dict(row) for row in cursor.fetchall()]
    
    def cleanup_expired(self) -> int:
        """
        æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆè¶…è¿‡24å°æ—¶ï¼‰
        
        Returns:
            åˆ é™¤çš„æ¡æ•°
        """
        cutoff_time = datetime.now() - timedelta(hours=self.RETENTION_HOURS)
        
        with self._get_conn() as conn:
            cursor = conn.execute(
                'DELETE FROM news WHERE crawled_at < ?',
                (cutoff_time.isoformat(),)
            )
            deleted = cursor.rowcount
        
        if deleted > 0:
            print(f"ğŸ§¹ æ¸…ç†äº† {deleted} æ¡è¿‡æœŸæ–°é—»ï¼ˆè¶…è¿‡ {self.RETENTION_HOURS} å°æ—¶ï¼‰")
        
        return deleted
    
    def get_stats(self) -> dict:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        with self._get_conn() as conn:
            cursor = conn.execute('SELECT COUNT(*) as total FROM news')
            total = cursor.fetchone()['total']
            
            cursor = conn.execute('''
                SELECT source, COUNT(*) as count 
                FROM news 
                GROUP BY source
            ''')
            by_source = {row['source']: row['count'] for row in cursor.fetchall()}
            
            cursor = conn.execute('''
                SELECT MIN(crawled_at) as oldest, MAX(crawled_at) as newest 
                FROM news
            ''')
            row = cursor.fetchone()
            
            return {
                'total': total,
                'by_source': by_source,
                'oldest': row['oldest'],
                'newest': row['newest'],
                'retention_hours': self.RETENTION_HOURS
            }


# å…¨å±€å•ä¾‹
_storage_instance: Optional[NewsStorage] = None

def get_storage() -> NewsStorage:
    """è·å–å­˜å‚¨å•ä¾‹"""
    global _storage_instance
    if _storage_instance is None:
        _storage_instance = NewsStorage()
    return _storage_instance


if __name__ == "__main__":
    # æµ‹è¯•
    storage = NewsStorage()
    
    # æµ‹è¯•æ•°æ®
    test_news = [
        {
            'id': 'test001',
            'source': 'PANews',
            'title': 'æµ‹è¯•æ–°é—»æ ‡é¢˜',
            'content': 'è¿™æ˜¯æµ‹è¯•å†…å®¹',
            'link': 'https://example.com',
            'time': '12:00',
            'crawled_at': datetime.now().isoformat()
        }
    ]
    
    inserted = storage.save_news(test_news)
    print(f"æ’å…¥ {inserted} æ¡")
    
    latest = storage.get_latest_news(limit=5)
    print(f"æœ€æ–° {len(latest)} æ¡:")
    for n in latest:
        print(f"  - {n['title']}")
    
    stats = storage.get_stats()
    print(f"ç»Ÿè®¡: {stats}")

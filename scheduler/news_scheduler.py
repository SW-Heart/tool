"""
æ–°é—»çˆ¬è™«å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
æ¯15åˆ†é’Ÿè‡ªåŠ¨æŠ“å– PANews é‡è¦èµ„è®¯
"""

import time
import logging
import signal
import sys
from datetime import datetime
from typing import List, Optional

import schedule

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(__file__).rsplit('/', 2)[0])

from crawlers.panews import PANewsCrawler
from crawlers.storage import get_storage

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/news_scheduler.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class NewsScheduler:
    """æ–°é—»çˆ¬è™«å®šæ—¶è°ƒåº¦å™¨"""
    
    # ç¨³å®šæ€§é…ç½®
    MAX_RETRIES = 3  # å•æ¬¡æŠ“å–æœ€å¤§é‡è¯•æ¬¡æ•°
    MAX_CONSECUTIVE_FAILURES = 5  # è¿ç»­å¤±è´¥é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™é‡ç½®çˆ¬è™«
    RETRY_DELAY_SECONDS = 5  # é‡è¯•é—´éš”
    
    def __init__(self, interval_minutes: int = 15):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            interval_minutes: çˆ¬å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤15åˆ†é’Ÿ
        """
        self.interval = interval_minutes
        self.crawler = PANewsCrawler(headless=True)
        self.storage = get_storage()
        self._running = False
        self._last_run: Optional[datetime] = None
        self._last_success: Optional[datetime] = None
        self._total_fetched = 0
        self._total_saved = 0
        self._consecutive_failures = 0
    
    def fetch_news(self):
        """æ‰§è¡Œä¸€æ¬¡æ–°é—»æŠ“å–ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        logger.info("=" * 50)
        logger.info(f"ğŸš€ å¼€å§‹æŠ“å– - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 50)
        
        self._last_run = datetime.now()
        last_error = None
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(self.MAX_RETRIES):
            try:
                # æŠ“å–æ–°é—»ï¼ˆè‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
                news = self.crawler.fetch_sync(only_new=True, save_to_db=True)
                
                # æˆåŠŸï¼šé‡ç½®å¤±è´¥è®¡æ•°
                self._consecutive_failures = 0
                self._last_success = datetime.now()
                self._total_fetched += len(news)
                
                if news:
                    logger.info(f"âœ… æˆåŠŸæŠ“å– {len(news)} æ¡æ–°èµ„è®¯")
                    for item in news[:3]:  # åªæ˜¾ç¤ºå‰3æ¡
                        logger.info(f"   ğŸ“° {item.get('time', '')} | {item['title'][:40]}...")
                    if len(news) > 3:
                        logger.info(f"   ... è¿˜æœ‰ {len(news) - 3} æ¡")
                else:
                    logger.info("â„¹ï¸ æš‚æ— æ–°èµ„è®¯")
                
                # æ˜¾ç¤ºç»Ÿè®¡
                stats = self.storage.get_stats()
                logger.info(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€: å…± {stats['total']} æ¡ï¼Œä¿ç•™ {stats['retention_hours']} å°æ—¶")
                logger.info("=" * 50)
                return  # æˆåŠŸåˆ™é€€å‡º
                
            except Exception as e:
                last_error = e
                if attempt < self.MAX_RETRIES - 1:
                    logger.warning(f"âš ï¸ æŠ“å–å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{self.MAX_RETRIES}: {e}")
                    time.sleep(self.RETRY_DELAY_SECONDS)
        
        # å…¨éƒ¨é‡è¯•å¤±è´¥
        self._consecutive_failures += 1
        logger.error(f"âŒ æŠ“å–å¤±è´¥ï¼ˆå·²é‡è¯•{self.MAX_RETRIES}æ¬¡ï¼‰: {last_error}")
        logger.error(f"âš ï¸ è¿ç»­å¤±è´¥æ¬¡æ•°: {self._consecutive_failures}/{self.MAX_CONSECUTIVE_FAILURES}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®çˆ¬è™«
        if self._consecutive_failures >= self.MAX_CONSECUTIVE_FAILURES:
            self._reset_crawler()
        
        logger.info("=" * 50)
    
    def _reset_crawler(self):
        """é‡ç½®çˆ¬è™«å®ä¾‹ï¼ˆè¿ç»­å¤±è´¥è¿‡å¤šæ—¶è°ƒç”¨ï¼‰"""
        logger.warning("ğŸ”„ è¿ç»­å¤±è´¥è¿‡å¤šï¼Œæ­£åœ¨é‡ç½®çˆ¬è™«å®ä¾‹...")
        try:
            # é‡æ–°åˆ›å»ºçˆ¬è™«å®ä¾‹
            self.crawler = PANewsCrawler(headless=True)
            self._consecutive_failures = 0
            logger.info("âœ… çˆ¬è™«å®ä¾‹å·²é‡ç½®")
        except Exception as e:
            logger.error(f"âŒ é‡ç½®çˆ¬è™«å¤±è´¥: {e}")
    
    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            deleted = self.storage.cleanup_expired()
            if deleted > 0:
                logger.info(f"ğŸ§¹ æ¸…ç†äº† {deleted} æ¡è¿‡æœŸæ–°é—»")
        except Exception as e:
            logger.error(f"æ¸…ç†å¤±è´¥: {e}")
    
    def setup_schedule(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        # æ¯ N åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
        schedule.every(self.interval).minutes.do(self.fetch_news)
        
        # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡è¿‡æœŸæ•°æ®
        schedule.every().hour.do(self.cleanup_expired)
        
        logger.info(f"â° å®šæ—¶ä»»åŠ¡å·²è®¾ç½®:")
        logger.info(f"   - æ¯ {self.interval} åˆ†é’ŸæŠ“å–æ–°é—»")
        logger.info(f"   - æ¯å°æ—¶æ¸…ç†è¿‡æœŸæ•°æ® (è¶…è¿‡24å°æ—¶)")
    
    def run(self, run_immediately: bool = True):
        """
        å¯åŠ¨è°ƒåº¦å™¨
        
        Args:
            run_immediately: æ˜¯å¦ç«‹å³æ‰§è¡Œä¸€æ¬¡
        """
        self._running = True
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        import os
        os.makedirs('logs', exist_ok=True)
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        self.setup_schedule()
        
        if run_immediately:
            logger.info("ğŸ”„ ç«‹å³æ‰§è¡Œä¸€æ¬¡æŠ“å–...")
            self.fetch_news()
        
        logger.info(f"âœ… è°ƒåº¦å™¨å·²å¯åŠ¨")
        logger.info(f"â³ ä¸‹æ¬¡æ‰§è¡Œ: {schedule.next_run()}")
        
        while self._running:
            schedule.run_pending()
            time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def _signal_handler(self, signum, frame):
        """å¤„ç†åœæ­¢ä¿¡å·"""
        logger.info("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
        self._running = False
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self._running = False
    
    def get_status(self) -> dict:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        return {
            'running': self._running,
            'interval_minutes': self.interval,
            'last_run': self._last_run.isoformat() if self._last_run else None,
            'last_success': self._last_success.isoformat() if self._last_success else None,
            'next_run': str(schedule.next_run()) if schedule.jobs else None,
            'total_fetched': self._total_fetched,
            'consecutive_failures': self._consecutive_failures,
            'storage_stats': self.storage.get_stats()
        }


def run_news_scheduler(interval: int = 15, run_immediately: bool = True):
    """
    è¿è¡Œæ–°é—»è°ƒåº¦å™¨
    
    Args:
        interval: æŠ“å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
        run_immediately: æ˜¯å¦ç«‹å³æ‰§è¡Œ
    """
    scheduler = NewsScheduler(interval_minutes=interval)
    scheduler.run(run_immediately=run_immediately)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ–°é—»çˆ¬è™«å®šæ—¶è°ƒåº¦å™¨")
    parser.add_argument(
        "--interval", "-i",
        type=int,
        default=15,
        help="æŠ“å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤15"
    )
    parser.add_argument(
        "--no-immediate",
        action="store_true",
        help="å¯åŠ¨æ—¶ä¸ç«‹å³æ‰§è¡Œ"
    )
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸ“° Crypto æ–°é—»çˆ¬è™«è°ƒåº¦å™¨")
    print("=" * 50)
    print(f"â° æŠ“å–é—´éš”: æ¯ {args.interval} åˆ†é’Ÿ")
    print(f"ğŸ’¾ æ•°æ®ä¿ç•™: 24 å°æ—¶")
    print(f"ğŸ“¡ æ•°æ®æ¥æº: PANews (é‡è¦èµ„è®¯)")
    print("=" * 50)
    
    run_news_scheduler(
        interval=args.interval,
        run_immediately=not args.no_immediate
    )
